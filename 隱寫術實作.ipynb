{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZB4EgWtGMbNH"
      },
      "source": [
        "æ¯æ¬¡æ“ä½œéƒ½è¦æŒ‰ã€ŒåŸ·è¡Œã€ï¼Œä¹Ÿå°±æ˜¯æ¡†æ¡†å·¦é‚Šçš„åœ“å½¢æŒ‰éˆ•\n",
        "\n",
        "é¦–å…ˆï¼Œè«‹å…ˆæŒ‰ä¸‹è¨­å®šå€ä¸‹é¢çš„æŒ‰éˆ•ï¼ŒåŸ·è¡Œæ‰€æœ‰å®‰è£è¨­å®š"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpRSClRdMM7T"
      },
      "source": [
        "## è¨­å®šå€"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3gVDAvaLyI8"
      },
      "source": [
        "### å®‰è£å¥—ä»¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "douT80wiJMmV"
      },
      "outputs": [],
      "source": [
        "!pip install Pillow numpy matplotlib librosa exif"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noVzxDulO9Oi"
      },
      "source": [
        "### EOF åµæ¸¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNjJP6KRNLq9"
      },
      "outputs": [],
      "source": [
        "def detect_EOF(file_path, num_bytes=256):\n",
        "    \"\"\"\n",
        "    Reads the last few bytes of a file and displays them in a hex and ASCII format\n",
        "    similar to the 'xxd' command.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): The full path to the file.\n",
        "        num_bytes (int): The number of bytes to read from the end of the file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'rb') as f:\n",
        "            f.seek(0, 2)  # Seek to the end of the file\n",
        "            file_size = f.tell()\n",
        "            f.seek(max(0, file_size - num_bytes), 0) # Seek back num_bytes from the end\n",
        "            data = f.read(num_bytes)\n",
        "\n",
        "        offset = max(0, file_size - num_bytes)\n",
        "        bytes_per_line = 16\n",
        "\n",
        "        for i in range(0, len(data), bytes_per_line):\n",
        "            hex_part = ' '.join([f'{b:02x}' for b in data[i:i+bytes_per_line]])\n",
        "            ascii_part = ''.join([chr(b) if 32 <= b <= 126 else '.' for b in data[i:i+bytes_per_line]])\n",
        "            print(f'{offset + i:08x}: {hex_part:<{bytes_per_line * 3 - 1}} {ascii_part}')\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{file_path}' was not found.\")\n",
        "        print(\"Please make sure the file is uploaded to your Colab environment and the path is correct.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bY1banGO_7v"
      },
      "source": [
        "### LSB åµæ¸¬ï¼‹è§£å¯†"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_Wm4O4hPEPx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def detect_LSB(image_path):\n",
        "    \"\"\"\n",
        "    Opens an image, extracts its LSB plane, and displays both images.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): The full path to the image file within the Colab environment.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # For visualization, RGB is sufficient and standard.\n",
        "        original_image = Image.open(image_path).convert('RGB')\n",
        "        image_array = np.array(original_image)\n",
        "        lsb_array = (image_array % 2) * 255\n",
        "        lsb_image = Image.fromarray(lsb_array.astype('uint8'), 'RGB')\n",
        "\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "        axes[0].imshow(original_image)\n",
        "        axes[0].set_title('Original Image')\n",
        "        axes[0].axis('off')\n",
        "\n",
        "        axes[1].imshow(lsb_image)\n",
        "        axes[1].set_title('LSB Visualization')\n",
        "        axes[1].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{image_path}' was not found.\")\n",
        "        print(\"Please make sure the file is uploaded to your Colab environment and the path is correct.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "def decode_LSB(image_path):\n",
        "    \"\"\"\n",
        "    Extracts a hidden message from an image's LSBs. If the message appears\n",
        "    to be a CSV file, it saves it. Otherwise, it prints the content.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): The path to the steganographic image file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # --- FIX: Convert to RGBA to match the web tool's encoding process ---\n",
        "        # The web encoder uses all 4 channels (R,G,B,A) to store data.\n",
        "        image = Image.open(image_path).convert('RGBA')\n",
        "        image_array = np.array(image)\n",
        "\n",
        "        binary_data = image_array.flatten() % 2\n",
        "        byte_data = np.packbits(binary_data)\n",
        "\n",
        "        # --- FIX: Decode using 'latin-1' for robustness. ---\n",
        "        # This encoding maps every possible byte value (0-255) to a character,\n",
        "        # preventing decoding errors that can happen with UTF-8 on raw binary data.\n",
        "        # This allows us to reliably find our text-based delimiter.\n",
        "        full_message = byte_data.tobytes().decode('latin-1')\n",
        "\n",
        "        delimiter = \"|||||\"\n",
        "        delimiter_index = full_message.find(delimiter)\n",
        "\n",
        "        if delimiter_index != -1:\n",
        "            revealed_message = full_message[:delimiter_index]\n",
        "\n",
        "            # Heuristic to check if the content is likely a CSV file\n",
        "            if ',' in revealed_message and '\\n' in revealed_message:\n",
        "                output_filename = 'decoded_output.csv'\n",
        "                try:\n",
        "                    with open(output_filename, 'w', newline='', encoding='utf-8') as f:\n",
        "                        f.write(revealed_message)\n",
        "                    print(f\"--- CSV Content Detected ---\")\n",
        "                    print(f\"Message saved to '{output_filename}' in your Colab session files.\")\n",
        "                    print(\"--------------------------\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Could not save the CSV file. Error: {e}\")\n",
        "            else:\n",
        "                # If not a CSV, just print the text content\n",
        "                print(\"--- Message Found ---\")\n",
        "                print(revealed_message)\n",
        "                print(\"---------------------\")\n",
        "        else:\n",
        "            print(\"No message with a valid delimiter found.\")\n",
        "            print(\"\\n--- Partial Data (Fallback) ---\")\n",
        "            print(full_message[:200])\n",
        "            print(\"-------------------------------\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{image_path}' was not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during decoding: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_abXSIH6FIZ"
      },
      "source": [
        "### åŸ¹æ ¹è§£å¯†"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMHMJPCs6IyA"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import time # Import the time module\n",
        "\n",
        "def decode_bacon(file_name, A_char, B_char):\n",
        "  try:\n",
        "    with open(file_name, 'r', encoding='utf-8') as file:\n",
        "        content = file.read()\n",
        "\n",
        "    ## 1. Extract and Group the A/B Sequence\n",
        "    # ----------------------------------------\n",
        "    print(\"## Task 1: Extracting A/B Sequence ##\\n\")\n",
        "    print(\"Extracting characters...\") # Progress indicator\n",
        "    time.sleep(1) # Add a small delay\n",
        "\n",
        "    ab_sequence = \"\"\n",
        "    for char in content:\n",
        "        if char == A_char:\n",
        "            ab_sequence += \"A\"\n",
        "        elif char == B_char:\n",
        "            ab_sequence += \"B\"\n",
        "\n",
        "    # Group the sequence into chunks of 5 characters\n",
        "    grouped_sequence = [ab_sequence[i:i+5] for i in range(0, len(ab_sequence), 5)]\n",
        "\n",
        "    print(\"Extracted A/B Sequence (in groups of 5):\")\n",
        "    print(' '.join(grouped_sequence))\n",
        "    print(\"-\" * 40)\n",
        "    time.sleep(1) # Add a small delay\n",
        "\n",
        "\n",
        "    ## 2. Create the Mapping CSV File\n",
        "    # ---------------------------------\n",
        "    print(\"\\n## Task 2: Reading Mapping File ##\\n\")\n",
        "    print(\"Reading mapping file...\") # Progress indicator\n",
        "    time.sleep(1) # Add a small delay\n",
        "\n",
        "    bacon_map = {}\n",
        "    csv_path = './decoded_output.csv'\n",
        "    try:\n",
        "        with open(csv_path, mode='r', encoding='utf-8') as csv_file:\n",
        "            reader = csv.reader(csv_file)\n",
        "            for row in reader:\n",
        "                if len(row) == 2:\n",
        "                    bacon_map[row[1]] = row[0]\n",
        "        print(f\"Baconian cipher mapping has been read from: {csv_path}\")\n",
        "        print(\"-\" * 40)\n",
        "        time.sleep(1) # Add a small delay\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The mapping file '{csv_path}' was not found.\")\n",
        "        print(\"Please make sure 'decoded_output.csv' exists in your Colab session files.\")\n",
        "        return # Exit if the mapping file is not found\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading the mapping file: {e}\")\n",
        "        return # Exit on other file reading errors\n",
        "\n",
        "\n",
        "    ## 3. Decode and Display the Message\n",
        "    # -----------------------------------\n",
        "    print(\"\\n## Task 3: Decoding the Message ##\\n\")\n",
        "    print(\"Decoding message...\") # Progress indicator\n",
        "    time.sleep(1) # Add a small delay\n",
        "\n",
        "\n",
        "    decoded_message = \"\"\n",
        "    for group in grouped_sequence:\n",
        "        # Ensure the group is a valid 5-character key\n",
        "        if group in bacon_map:\n",
        "            decoded_message += bacon_map[group]\n",
        "        else:\n",
        "            decoded_message += \"?\" # Add a placeholder for unknown sequences\n",
        "\n",
        "    print(\"ğŸ‰ The decoded secret message is:\")\n",
        "    print(decoded_message.upper())\n",
        "\n",
        "  except FileNotFoundError:\n",
        "      print(f\"Error: The input file '{file_name}' was not found.\")\n",
        "      print(\"Please make sure the file is uploaded to your Colab environment and the path is correct.\")\n",
        "  except Exception as e:\n",
        "      print(f\"An error occurred during Baconian decoding: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip-L40XF5sy4"
      },
      "source": [
        "### é »è­œè§£å¯†"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdAC_rYR5vEK"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from IPython.display import Audio, display # Import Audio and display\n",
        "\n",
        "def decode_spectrogram(audio_path):\n",
        "  try:\n",
        "    # Load file\n",
        "    y, sr = librosa.load(audio_path)\n",
        "\n",
        "    # Play the audio file\n",
        "    print(\"Playing audio...\")\n",
        "    display(Audio(y, rate=sr))\n",
        "\n",
        "    # Compute the short-time Fourier transform (STFT)\n",
        "    D = librosa.stft(y)\n",
        "\n",
        "    # Convert to magnitude\n",
        "    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
        "\n",
        "    # Plot with log-frequency scale\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    librosa.display.specshow(S_db, sr=sr, x_axis='time', y_axis='log')\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.title('Spectrogram')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "  except FileNotFoundError:\n",
        "    print(f\"Error: The audio file '{audio_path}' was not found.\")\n",
        "    print(\"Please make sure the file is uploaded to your Colab environment and the path is correct.\")\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred during spectrogram decoding: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc2qgPR3s6Hv"
      },
      "source": [
        "### metadata è§£å¯†"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kI6lycVos9Nv"
      },
      "outputs": [],
      "source": [
        "import exif\n",
        "\n",
        "def decode_meta(file_path):\n",
        "    \"\"\"\n",
        "    Extracts metadata from an image file using the exif package.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): The path to the image file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'rb') as f:\n",
        "            img = exif.Image(f)\n",
        "\n",
        "        if img.has_exif:\n",
        "            print(f\"Metadata for {file_path}:\")\n",
        "            if 'user_comment' in img.list_all():\n",
        "                print(\"User Comment:\")\n",
        "                print(img.get('user_comment'))\n",
        "            else:\n",
        "                print(\"No user comment found.\")\n",
        "            #for tag in img.list_all():\n",
        "                # You can filter for specific tags if needed, e.g., 'user_comment'\n",
        "                # if 'user' in tag.lower():\n",
        "                #print(f\"{tag}: {img.get(tag)}\")\n",
        "        else:\n",
        "            print(f\"No EXIF metadata found in {file_path}.\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{file_path}' was not found.\")\n",
        "        print(\"Please make sure the file is uploaded to your Colab environment and the path is correct.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during metadata decoding: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_wfr9EIMxij"
      },
      "source": [
        "# éš±å¯«è¡“æ“ä½œ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdKmQ7avGL4O"
      },
      "source": [
        "æŠŠæª”æ¡ˆä¸Šå‚³åˆ°å·¦é‚Šçš„è¦–çª—\n",
        "\n",
        "åœ¨ä½ æƒ³è™•ç†çš„æª”æ¡ˆä¸Šæ–¹æŒ‰å³éµå¾Œé¸æ“‡ã€Œè¤‡è£½è·¯å¾‘ã€\n",
        "\n",
        "æŠŠè·¯å¾‘è²¼åœ¨å–®å¼•è™Ÿ '' çš„è£¡é¢\n",
        "\n",
        "ç¯„ä¾‹ï¼š\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "file = '/content/example.jpg'\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsR52mVWGUK-"
      },
      "outputs": [],
      "source": [
        "file = ''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4w-U7fcHvE0"
      },
      "source": [
        "è²¼ä¸Šå¾Œè¨˜å¾—è¦åŸ·è¡Œå–”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okolwJGqFwVQ"
      },
      "source": [
        "## éš±å¯«åµæ¸¬"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1uSdxzuGAZX"
      },
      "source": [
        "### EOF åµæ¸¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EgZj0H6FSX3"
      },
      "outputs": [],
      "source": [
        "detect_EOF(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FguhOE3-Icns"
      },
      "source": [
        "### LSB åµæ¸¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LIKyb3oJ-HF"
      },
      "outputs": [],
      "source": [
        "detect_LSB(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enRgAU6ZParf"
      },
      "source": [
        "## éš±å¯«è§£ç¢¼"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iroge5adRE3_"
      },
      "source": [
        "### LSB è§£ç¢¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4r5lj0MlaodI"
      },
      "outputs": [],
      "source": [
        "decode_LSB(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEyXBrUuRJAC"
      },
      "source": [
        "### åŸ¹æ ¹è§£ç¢¼\n",
        "è«‹å…ˆè¼¸å…¥ A å’Œ B åˆ†åˆ¥æ˜¯ä»€éº¼\n",
        "ä¾‹å¦‚ï¼š\n",
        "\n",
        "```\n",
        "A = '1'\n",
        "B = '2'\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUFH5aU26L0R"
      },
      "outputs": [],
      "source": [
        "A = ''\n",
        "B = ''\n",
        "decode_bacon(file, A, B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bK5FivXRMsf"
      },
      "source": [
        "### é »è­œè§£ç¢¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Eqj4lkO58W9"
      },
      "outputs": [],
      "source": [
        "decode_spectrogram(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz1ctybltLv5"
      },
      "source": [
        "### metadata è§£ç¢¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhWzI268tOVt"
      },
      "outputs": [],
      "source": [
        "decode_meta(file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
